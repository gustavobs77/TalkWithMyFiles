# Talking with my files

Este projeto implementa um chatbot baseado em **RAG (Retrieval-Augmented Generation)** usando **Streamlit** para interaÃ§Ã£o, permitindo que usuÃ¡rios faÃ§am perguntas baseadas no conteÃºdo de documentos PDF.

## ğŸ“Œ Funcionalidades
- Upload de arquivos **PDF** para extraÃ§Ã£o de informaÃ§Ãµes.
- Uso de **FAISS** para indexaÃ§Ã£o vetorial e recuperaÃ§Ã£o eficiente de documentos.
- GeraÃ§Ã£o de **embeddings** com **Hugging Face Embeddings (BAAI/bge-m3)**.
- Suporte a diferentes modelos de linguagem, como **Hugging Face Hub** e **Ollama**.
- HistÃ³rico de chat armazenado para contexto de conversaÃ§Ã£o.
- Respostas geradas pelo modelo com referÃªncia Ã s fontes nos documentos.

## ğŸ› ï¸ Tecnologias Utilizadas
- **Python**
- **Streamlit**
- **LangChain** (para configuraÃ§Ã£o do RAG)
- **FAISS** (indexaÃ§Ã£o e busca vetorial)
- **Hugging Face Embeddings** (transformaÃ§Ã£o de texto em vetores)
- **PyPDFLoader** (extraÃ§Ã£o de texto de PDFs)
- **Ollama / Hugging Face Hub** (modelos de linguagem para geraÃ§Ã£o de respostas)

## ğŸš€ Como Executar
1. Clone este repositÃ³rio:
   ```sh
   git clone https://github.com/seu-repositorio.git
   cd seu-repositorio
   ```
2. Instale as dependÃªncias:
   ```sh
   pip install -r requirements.txt
   ```
3. Configure suas credenciais (se necessÃ¡rio, por exemplo, para Hugging Face Hub ou OpenAI):
   ```sh
   export HUGGINGFACEHUB_API_TOKEN='seu_token_aqui'
   export OPENAI_API_KEY='seu_token_aqui'
   ```
4. Execute a aplicaÃ§Ã£o:
   ```sh
   streamlit run app.py
   ```
5. Acesse no navegador: `http://localhost:8501`

## ğŸ“‚ Estrutura do Projeto
```
ğŸ“‚ talking-with-my-files
â”œâ”€â”€ app.py                 # CÃ³digo principal
â”œâ”€â”€ requirements.txt       # DependÃªncias do projeto
â”œâ”€â”€ .env                   # VariÃ¡veis de ambiente
â”œâ”€â”€ ğŸ“‚ vectorstore         # Armazena a base FAISS
â””â”€â”€ README.md              # DocumentaÃ§Ã£o do projeto
```

## ğŸ“ Como Funciona
1. O usuÃ¡rio faz upload de um ou mais arquivos **PDF**.
2. O conteÃºdo Ã© processado e convertido em **vetores (embeddings)**.
3. A base de dados vetorial Ã© criada e armazenada usando **FAISS**.
4. O usuÃ¡rio faz uma pergunta na interface.
5. O sistema busca os trechos mais relevantes no **FAISS**.
6. O modelo de linguagem selecionado gera uma resposta baseada nesses trechos.
7. A resposta Ã© exibida junto com as fontes extraÃ­das do documento.

## ğŸ“Œ PossÃ­veis Melhorias
- Suporte a mais tipos de arquivos (ex: `.txt`, `.docx`).
- Ajuste fino nos **modelos de embedding** para melhorar a recuperaÃ§Ã£o de informaÃ§Ãµes.
- PersonalizaÃ§Ã£o da interface no Streamlit.

## ğŸ¤ ContribuiÃ§Ã£o
Sinta-se Ã  vontade para abrir issues, enviar PRs ou sugerir melhorias!

---

ğŸ”— **Contato**: [Seu Nome](https://linkedin.com/in/seu-perfil) | âœ‰ï¸ Email: seuemail@example.com


